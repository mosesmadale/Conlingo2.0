data("USArrests")
df_arrest <- USArrests
glimpse(df_arrest)
library(dplyr)
data("USArrests")
df_arrest <- USArrests
glimpse(df_arrest)
summary(df_arrest)
library(tidyverse)      # For tidy tools
library(tidyclust)
data("USArrests")
df_arrest <- USArrests
# Initial Data Analysis (IDA) for arrest data
glimpse(df_arrest)
summary(df_arrest)
sapply(df_arrest,
function(x) sum(is.na(x)))
sapply(df_arrest,
function(x) sum(is.na(x)))
library(tidyclust)
library(tidyverse)      # For tidy tools
install.packages("tidyclust")
library(tidyclust)
library(factoextra)
library(tidyverse)      # For tidy tools
install.packages("tidyclust")
library(tidyclust)
install.packages("factoextra")
library(factoextra)
install.packages("tidyclust")
data("USArrests")
df_arrest <- USArrests
# Initial Data Analysis (IDA) for arrest data
glimpse(df_arrest)
summary(df_arrest)
#Look for missing values
sapply(df_arrest,
function(x) sum(is.na(x)))
# Check column means and standard deviations
apply(df_arrest,2,mean)
apply(df_arrest,2,sd)
mx_arrest_scaled <- scale(df_arrest, center = TRUE, scale = TRUE)
df_arrest_scaled <- as_tibble(df_arrest, rownames = NA)
summary(df_arrest)
fviz_nbclust(df_arrest_scaled, kmeans, method = "wss")
fviz_nbclust(df_arrest_scaled, kmeans, method = "gap_stat")
fviz_nbclust(df_arrest_scaled, kmeans, method = "silhouette")
fviz_nbclust(df_arrest_scaled, kmeans, method = "wss")
fviz_nbclust(df_arrest_scaled, kmeans, method = "gap_stat")
fviz_nbclust(df_arrest_scaled, kmeans, method = "gap_stat")
fviz_nbclust(df_arrest_scaled, kmeans, method = "gap_stat")
fviz_nbclust(df_arrest_scaled, kmeans, method = "gap_stat")
fviz_nbclust(df_arrest_scaled, kmeans, method = "wss")
fviz_nbclust(df_arrest_scaled, kmeans, method = "gap_stat")
fviz_nbclust(df_arrest_scaled, kmeans, method = "silhouette")
fviz_nbclust(df_arrest_scaled, kmeans, method = "wss")
set.seed(1234)  # For reproducible results
set.seed(1234)  # For reproducible results
# Create a k-means model specification
kmeans_arrest_spec <- k_means(num_clusters  = 4) %>%
set_engine("stats")
# Create a k-means model using the specification
kmeans_arrest_fit <- kmeans_arrest_spec %>%
fit(~., data=df_arrest_scaled)
##############################################
# Telco Customer Churn - Logistic Regression
# Using tidyverse + tidymodels
# Author: Rohan Aby
##############################################
# Install packages if needed
if (!require(tidyverse)) install.packages("tidyverse")
if (!require(tidymodels)) install.packages("tidymodels")
if (!require(tidymodels)) install.packages("janitor")
#install.packages("plotROC")
library(tidyverse)
library(tidymodels)
library(janitor)
library(yardstick)
library(plotROC)
#1. read the file into a tibble
telco <- read_csv("Telco-Customer-Churn.csv")
# Install packages if needed
if (!require(tidyverse)) install.packages("tidyverse")
if (!require(tidymodels)) install.packages("tidymodels")
if (!require(tidymodels)) install.packages("janitor")
#install.packages("plotROC")
library(tidyverse)
library(tidymodels)
library(janitor)
library(yardstick)
library(plotROC)
telco <- read_csv("Telco-Customer-Churn.csv")
telco <- read_csv("Telco-Customer-Churn.csv")
#install.packages("plotROC")
library(tidyverse)
library(tidymodels)
library(janitor)
library(yardstick)
library(plotROC)
#1. read the file into a tibble
telco <- read_csv("Telco-Customer-Churn.csv")
library(tidyverse)
library(tidymodels)
library(janitor)
library(yardstick)
library(plotROC)
#1. read the file into a tibble
script_dir <-dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(script_dir)
data_path <- file.path("..","Telco-Customer-Churn.csv")
telco <- read_csv(data_path)
# Install packages if needed
if (!require(tidyverse)) install.packages("tidyverse")
if (!require(tidymodels)) install.packages("tidymodels")
if (!require(tidymodels)) install.packages("janitor")
#install.packages("plotROC")
library(tidyverse)
library(tidymodels)
library(janitor)
library(yardstick)
library(plotROC)
library(readr)
data_path <- "/Users/theeagleeye/Desktop/Telco-Customer-Churn.csv"
telco <- read_csv(data_path)
glimpse(telco)
telco <- telco %>% drop_na()
telco$Churn <- as.factor(telco$Churn)
glimpse(telco)
telco <- telco %>%
mutate(
TotalCharges = as.numeric(TotalCharges),
SeniorCitizen = as.factor(SeniorCitizen),
Churn = as.factor(Churn)
)
telco <- telco %>%
mutate(across(where(is.character), as.factor))
glimpse(telco)
set.seed(123)
data_split <- initial_split(telco, prop = 0.8, strata = Churn)
train_data <- training(data_split)
test_data  <- testing(data_split)
model_full <- glm(Churn ~ . -customerID, data = train, family = binomial)
model_full <- glm(Churn ~ . -customerID, data = train, family = binomial)
model_full <- glm(Churn ~ . -customerID, data = train_data, family = binomial)
summary(model_full)
model_reduced <- glm(
Churn ~ SeniorCitizen + tenure + PhoneService + InternetService +
Contract + PaperlessBilling + PaymentMethod + TotalCharges,
data = train_data,
family = binomial
)
summary(model_reduced)
model_reduced <- glm(
Churn ~ SeniorCitizen + tenure + PhoneService + InternetService +
Contract + PaperlessBilling + PaymentMethodElectronic.check + TotalCharges,
data = train_data,
family = binomial
)
model_reduced <- glm(
Churn ~ SeniorCitizen + tenure + PhoneService + InternetService +
Contract + PaperlessBilling + PaymentMethodElectronic.check + TotalCharges,
data = train_data,
family = binomial
)
# Keep only the levels we want to include
train_data <- train_data %>%
mutate(PaymentMethod = factor(PaymentMethod,
levels = c("Electronic check")))
test_data <- test_data %>%
mutate(PaymentMethod = factor(PaymentMethod,
levels = c("Electronic check")))
model_reduced <- glm(
Churn ~ SeniorCitizen + tenure + PhoneService + InternetService +
Contract + PaperlessBilling + PaymentMethodElectronic.check + TotalCharges,
data = train_data,
family = binomial
)
model_reduced <- glm(
Churn ~ SeniorCitizen + tenure + PhoneService + InternetService +
Contract + PaperlessBilling + PaymentMethodElectronic.check + TotalCharges,
data = train_data,
family = binomial
)
# Rebuild logistic regression with only significant variables
model_reduced <- glm(
Churn ~ SeniorCitizen + tenure + PhoneService + InternetService +
Contract + PaperlessBilling + PaymentMethod + TotalCharges,
data = train_data,
family = binomial
)
# Rebuild logistic regression with only significant variables
model_reduced <- glm(
Churn ~ SeniorCitizen + tenure + PhoneService + InternetService +
Contract + PaperlessBilling + PaymentMethod + TotalCharges,
data = train_data,
family = binomial
)
# Rebuild logistic regression with only significant variables
model_reduced <- glm(
Churn ~ SeniorCitizen + tenure + PhoneService + InternetService +
Contract + PaperlessBilling + PaymentMethod + TotalCharges,
data = train_data,
family = binomial
)
if (!require(tidyverse)) install.packages("tidyverse")
if (!require(tidymodels)) install.packages("tidymodels")
if (!require(tidymodels)) install.packages("janitor")
#install.packages("plotROC")
library(tidyverse)
library(tidymodels)
library(janitor)
library(yardstick)
library(plotROC)
library(readr)
data_path <- "/Users/theeagleeye/Desktop/Telco-Customer-Churn.csv"
telco <- read_csv(data_path)
glimpse(telco)
#2.  Remove any rows that have NA's
telco <- telco %>% drop_na()
telco$Churn <- as.factor(telco$Churn)
# View structure
glimpse(telco)
telco <- telco %>%
mutate(
TotalCharges = as.numeric(TotalCharges),
SeniorCitizen = as.factor(SeniorCitizen),
Churn = as.factor(Churn)
)
telco <- telco %>%
mutate(across(where(is.character), as.factor))
# Inspect types
glimpse(telco)
#4.Split the data
set.seed(123)
data_split <- initial_split(telco, prop = 0.8, strata = Churn)
train_data <- training(data_split)
test_data  <- testing(data_split)
model_full <- glm(Churn ~ . -customerID, data = train_data, family = binomial)
summary(model_full)
model_reduced <- glm(
Churn ~ SeniorCitizen + tenure + PhoneService + InternetService +
Contract + PaperlessBilling + PaymentMethod + TotalCharges,
data = train_data,
family = binomial
)
summary(model_reduced)
library(dplyr)
library(tibble)
#Generate predicted probabilities on the test dataset
test_probs <- predict(model_reduced, newdata = test_data, type = "response")
library(dplyr)
library(tibble)
#Generate predicted probabilities on the test dataset
test_probs <- predict(model_reduced, newdata = test_data, type = "response")
# Using 0.5 as cutoff
test_pred <- ifelse(test_probs >= 0.5, "Yes", "No")
test_pred <- factor(test_pred, levels = c("No", "Yes"))
results <- test_data %>%
select(customerID, Churn) %>%
mutate(
predicted_probability = test_probs,
predicted_class = test_pred
) %>%
as_tibble()
head(results)
library(yardstick)
results <- results %>%
mutate(
Churn = factor(Churn, levels = c("No", "Yes")),
predicted_class = factor(predicted_class, levels = c("No", "Yes"))
)
#Confusion Matrix
conf_matrix <- conf_mat(results, truth = Churn, estimate = predicted_class)
conf_matrix
#Accuracy
acc <- accuracy(results, truth = Churn, estimate = predicted_class)
acc
#Sensitivity (True Positive Rate)
sens <- sens(results, truth = Churn, estimate = predicted_class)
sens
#Specificity (True Negative Rate)
spec <- spec(results, truth = Churn, estimate = predicted_class)
spec
library(ggplot2)
results <- results %>%
mutate(
Churn = factor(Churn, levels = c("No", "Yes"))
)
#Calculate ROC data
roc_data <- roc_curve(results, truth = Churn, .pred = predicted_probability)
library(ggplot2)
results <- results %>%
mutate(
Churn = factor(Churn, levels = c("No", "Yes"))
)
roc_data <- roc_curve(results, truth = Churn, .pred = predicted_probability)
results <- results %>%
rename(.pred_Yes = predicted_probability) %>%
mutate(Churn = factor(Churn, levels = c("No", "Yes")))
#Calculate ROC data
roc_data <- roc_curve(results, truth = Churn, .pred_Yes)
ggplot(roc_data, aes(x = 1 - specificity, y = sensitivity)) +
geom_line(color = "blue", size = 1.2) +
geom_abline(lty = 2, color = "gray") +
labs(
title = "ROC Curve for Churn Prediction",
x = "False Positive Rate (1 - Specificity)",
y = "True Positive Rate (Sensitivity)"
) +
theme_minimal()
roc_auc_val <- roc_auc(results, truth = Churn, .pred_Yes)
roc_auc_val
results <- results %>%
mutate(
Churn = factor(Churn, levels = c("No", "Yes"))  # "Yes" = positive class
)
results <- results %>%
mutate(
Churn = factor(Churn, levels = c("No", "Yes"))  # "Yes" = positive class
)
results <- results %>%
rename(.pred_Yes = predicted_probability)
library(ggplot2)
# 1️⃣ Check column names
colnames(results)
results <- results %>%
mutate(Churn = factor(Churn, levels = c("No", "Yes")))
roc_data <- roc_curve(results, truth = Churn, .pred_Yes)
ggplot(roc_data, aes(x = 1 - specificity, y = sensitivity)) +
geom_line(color = "blue", size = 1.2) +
geom_abline(lty = 2, color = "gray") +
labs(
title = "ROC Curve for Churn Prediction",
x = "False Positive Rate (1 - Specificity)",
y = "True Positive Rate (Sensitivity)"
) +
theme_minimal()
roc_auc_val <- roc_auc(results, truth = Churn, .pred_Yes)
roc_auc_val
library(ggplot2)
results <- results %>%
mutate(Churn = factor(Churn, levels = c("No", "Yes")))
# Flip probabilities if they are reversed
results <- results %>%
mutate(.pred_Yes = 1 - .pred_Yes)
roc_data <- roc_curve(results, truth = Churn, .pred_Yes)
roc_auc_val <- roc_auc(results, truth = Churn, .pred_Yes)
ggplot(roc_data, aes(x = 1 - specificity, y = sensitivity)) +
geom_line(color = "blue", size = 1.2) +
geom_abline(lty = 2, color = "gray") +
labs(
title = "ROC Curve for Churn Prediction",
x = "False Positive Rate (1 - Specificity)",
y = "True Positive Rate (Sensitivity)"
) +
theme_minimal()
roc_auc_val <- roc_auc(results, truth = Churn, .pred_Yes)
roc_auc_val
source("~/.active-rstudio-document", echo = TRUE)
